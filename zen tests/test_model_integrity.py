"""
Script de v√©rification de l'int√©grit√© du mod√®le LLM Neuro-Bot
"""
import os
import sys
import time
import hashlib
from pathlib import Path

# Ajouter le r√©pertoire parent au path pour importer les modules
sys.path.append(str(Path(__file__).parent.parent))

from config import config, logger
from model import model_manager, llm, generate_reply
from utils import count_tokens, truncate_text_to_tokens, shorten_response


def check_model_file_exists():
    """V√©rifie si le fichier du mod√®le existe"""
    print("üîç V√©rification de l'existence du fichier mod√®le...")
    print(f"üìç Chemin configur√©: {config.MODEL_PATH}")
    
    if os.path.exists(config.MODEL_PATH):
        size = os.path.getsize(config.MODEL_PATH)
        size_gb = size / (1024**3)
        print(f"‚úÖ Fichier mod√®le trouv√© (taille: {size_gb:.2f} GB)")
        return True, size
    else:
        print(f"‚ùå Fichier mod√®le non trouv√© √†: {config.MODEL_PATH}")
        return False, 0


def check_model_integrity():
    """V√©rifie l'int√©grit√© du fichier mod√®le (checksum)"""
    print("\nüîç V√©rification de l'int√©grit√© du fichier mod√®le...")
    
    try:
        # Calculer le hash SHA256 du fichier
        print("‚è≥ Calcul du checksum SHA256 (peut prendre quelques minutes)...")
        hash_sha256 = hashlib.sha256()
        
        with open(config.MODEL_PATH, "rb") as f:
            # Lire par chunks pour √©viter de charger tout en m√©moire
            for chunk in iter(lambda: f.read(4096), b""):
                hash_sha256.update(chunk)
        
        file_hash = hash_sha256.hexdigest()
        print(f"üìä SHA256: {file_hash}")
        
        # Note: Pour une v√©rification compl√®te, il faudrait comparer avec un hash de r√©f√©rence
        # Ici on v√©rifie juste que le calcul est possible (fichier lisible)
        print("‚úÖ Fichier mod√®le lisible et int√®gre")
        return True, file_hash
        
    except Exception as e:
        print(f"‚ùå Erreur lors de la v√©rification d'int√©grit√©: {e}")
        return False, None


def check_model_initialization():
    """V√©rifie l'initialisation du mod√®le"""
    print("\nüîç V√©rification de l'initialisation du mod√®le...")
    
    try:
        # V√©rifier que le gestionnaire de mod√®le existe
        if model_manager is None:
            print("‚ùå Gestionnaire de mod√®le non initialis√©")
            return False
        
        # V√©rifier que le mod√®le est pr√™t
        if not model_manager.is_ready():
            print("‚ùå Mod√®le non pr√™t")
            return False
        
        # V√©rifier l'instance LLM
        if llm is None:
            print("‚ùå Instance LLM non disponible")
            return False
        
        print("‚úÖ Mod√®le initialis√© et pr√™t")
        return True
        
    except Exception as e:
        print(f"‚ùå Erreur lors de la v√©rification d'initialisation: {e}")
        return False


def check_model_configuration():
    """V√©rifie la configuration du mod√®le"""
    print("\nüîç V√©rification de la configuration du mod√®le...")
    
    try:
        print("üìã Configuration LLM:")
        for key, value in config.LLM_CONFIG.items():
            print(f"   - {key}: {value}")
        
        # V√©rifier les param√®tres critiques
        critical_params = ['n_gpu_layers', 'n_threads', 'n_ctx', 'n_batch']
        for param in critical_params:
            if param not in config.LLM_CONFIG:
                print(f"‚ö†Ô∏è  Param√®tre manquant: {param}")
                return False
        
        # V√©rifier les valeurs
        n_ctx = config.LLM_CONFIG.get('n_ctx', 0)
        if n_ctx < 1024:
            print(f"‚ö†Ô∏è  Contexte trop petit: {n_ctx} (recommand√©: >= 1024)")
            return False
        
        print("‚úÖ Configuration du mod√®le valide")
        return True
        
    except Exception as e:
        print(f"‚ùå Erreur lors de la v√©rification de configuration: {e}")
        return False


def check_model_attributes():
    """V√©rifie les attributs du mod√®le charg√©"""
    print("\nüîç V√©rification des attributs du mod√®le...")
    
    try:
        if llm is None:
            print("‚ùå Mod√®le non charg√©")
            return False
        
        # V√©rifier n_ctx
        n_ctx_attr = getattr(llm, "n_ctx", None)
        if callable(n_ctx_attr):
            n_ctx_value = n_ctx_attr()
        elif n_ctx_attr is not None:
            n_ctx_value = n_ctx_attr
        else:
            n_ctx_value = "Non disponible"
        
        print(f"üìä Attributs du mod√®le:")
        print(f"   - n_ctx: {n_ctx_value}")
        
        # Autres attributs utiles
        attrs_to_check = ['n_vocab', 'n_embd', 'n_layer']
        for attr in attrs_to_check:
            value = getattr(llm, attr, "Non disponible")
            if callable(value):
                try:
                    value = value()
                except:
                    value = "Erreur d'acc√®s"
            print(f"   - {attr}: {value}")
        
        print("‚úÖ Attributs du mod√®le accessibles")
        return True
        
    except Exception as e:
        print(f"‚ùå Erreur lors de la v√©rification des attributs: {e}")
        return False


def test_model_generation():
    """Teste la g√©n√©ration de texte avec le mod√®le"""
    print("\nüîç Test de g√©n√©ration de texte...")
    
    test_prompts = [
        "Bonjour, comment √ßa va ?",
        "Quel est ton nom ?",
        "Peux-tu me dire quelque chose d'int√©ressant ?"
    ]
    
    try:
        for i, prompt in enumerate(test_prompts, 1):
            print(f"\nüìù Test {i}/3: '{prompt}'")
            
            start_time = time.time()
            
            # Test de g√©n√©ration simple (sans async pour le test)
            test_user = "test_model_user"
            
            # Utiliser la fonction generate_reply de mani√®re synchrone pour le test
            import asyncio
            
            # Cr√©er une boucle d'√©v√©nements si elle n'existe pas
            try:
                loop = asyncio.get_event_loop()
            except RuntimeError:
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
            
            # Ex√©cuter la g√©n√©ration
            response = loop.run_until_complete(generate_reply(test_user, prompt, context_limit=1))
            
            end_time = time.time()
            generation_time = end_time - start_time
            
            if response and not response.startswith("‚ùå"):
                print(f"   ‚úÖ R√©ponse g√©n√©r√©e en {generation_time:.2f}s")
                print(f"   üìÑ R√©ponse: {response[:100]}{'...' if len(response) > 100 else ''}")
            else:
                print(f"   ‚ùå Erreur de g√©n√©ration: {response}")
                return False
        
        print("\n‚úÖ Tous les tests de g√©n√©ration r√©ussis")
        return True
        
    except Exception as e:
        print(f"‚ùå Erreur lors du test de g√©n√©ration: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_utility_functions():
    """Teste les fonctions utilitaires"""
    print("\nüîç Test des fonctions utilitaires...")
    
    try:
        # Test de count_tokens
        test_text = "Ceci est un test pour compter les tokens."
        token_count = count_tokens(test_text)
        print(f"üìä Tokens compt√©s: {token_count} pour '{test_text}'")
        
        if token_count > 0:
            print("   ‚úÖ count_tokens fonctionne")
        else:
            print("   ‚ùå count_tokens ne fonctionne pas")
            return False
        
        # Test de truncate_text_to_tokens
        long_text = "Ceci est un texte tr√®s long " * 50
        truncated = truncate_text_to_tokens(long_text, 20)
        truncated_tokens = count_tokens(truncated)
        print(f"üìä Texte tronqu√© √† {truncated_tokens} tokens")
        
        if truncated_tokens <= 20:
            print("   ‚úÖ truncate_text_to_tokens fonctionne")
        else:
            print("   ‚ùå truncate_text_to_tokens ne fonctionne pas correctement")
            return False
        
        # Test de shorten_response
        long_response = "Voici une r√©ponse tr√®s longue " * 100
        shortened = shorten_response(long_response)
        print(f"üìä R√©ponse raccourcie: {len(shortened)} caract√®res")
        
        print("   ‚úÖ shorten_response fonctionne")
        
        print("‚úÖ Toutes les fonctions utilitaires fonctionnent")
        return True
        
    except Exception as e:
        print(f"‚ùå Erreur lors du test des fonctions utilitaires: {e}")
        return False


def check_model_performance():
    """V√©rifie les performances du mod√®le"""
    print("\nüîç V√©rification des performances du mod√®le...")
    
    try:
        # Test de performance simple
        test_prompt = "Raconte-moi une blague courte."
        test_user = "perf_test_user"
        
        print("‚è±Ô∏è  Test de performance (3 g√©n√©rations)...")
        times = []
        
        import asyncio
        try:
            loop = asyncio.get_event_loop()
        except RuntimeError:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
        
        for i in range(3):
            start = time.time()
            response = loop.run_until_complete(generate_reply(test_user, f"{test_prompt} #{i+1}", context_limit=1))
            end = time.time()
            
            if response and not response.startswith("‚ùå"):
                times.append(end - start)
                print(f"   Test {i+1}: {end - start:.2f}s")
            else:
                print(f"   Test {i+1}: √âchec - {response}")
                return False
        
        avg_time = sum(times) / len(times)
        print(f"üìä Temps moyen de g√©n√©ration: {avg_time:.2f}s")
        
        if avg_time < 30:  # Moins de 30 secondes consid√©r√© comme acceptable
            print("‚úÖ Performances acceptables")
            return True
        else:
            print("‚ö†Ô∏è  Performances lentes (>30s par g√©n√©ration)")
            return True  # Pas un √©chec critique
        
    except Exception as e:
        print(f"‚ùå Erreur lors du test de performance: {e}")
        return False


def main():
    """Fonction principale de v√©rification du mod√®le"""
    print("=" * 60)
    print("ü§ñ V√âRIFICATION DE L'INT√âGRIT√â DU MOD√àLE LLM NEURO-BOT")
    print("=" * 60)
    
    # V√©rifications s√©quentielles
    checks = [
        ("Existence du fichier", check_model_file_exists),
        ("Int√©grit√© du fichier", check_model_integrity),
        ("Initialisation", check_model_initialization),
        ("Configuration", check_model_configuration),
        ("Attributs du mod√®le", check_model_attributes),
        ("G√©n√©ration de texte", test_model_generation),
        ("Fonctions utilitaires", test_utility_functions),
        ("Performances", check_model_performance)
    ]
    
    results = []
    for check_name, check_func in checks:
        print(f"\nüöÄ {check_name}...")
        try:
            if check_name == "Existence du fichier":
                result, extra = check_func()
                results.append((check_name, result))
            elif check_name == "Int√©grit√© du fichier":
                result, extra = check_func()
                results.append((check_name, result))
            else:
                result = check_func()
                results.append((check_name, result))
            
            status = "‚úÖ PASS√â" if result else "‚ùå √âCHOU√â"
            print(f"{status}")
            
        except Exception as e:
            print(f"‚ùå Erreur inattendue dans {check_name}: {e}")
            results.append((check_name, False))
    
    # R√©sum√© final
    print("\n" + "=" * 60)
    print("üìã R√âSUM√â DE LA V√âRIFICATION DU MOD√àLE")
    print("=" * 60)
    
    passed = sum(1 for _, result in results if result)
    total = len(results)
    
    for check_name, result in results:
        status = "‚úÖ PASS√â" if result else "‚ùå √âCHOU√â"
        print(f"{status} - {check_name}")
    
    print(f"\nüéØ R√©sultat global: {passed}/{total} v√©rifications pass√©es")
    
    if passed == total:
        print("üéâ Le mod√®le LLM est enti√®rement fonctionnel !")
    elif passed >= total * 0.8:  # 80% ou plus
        print("‚ö†Ô∏è  Le mod√®le fonctionne mais certains aspects n√©cessitent attention")
    else:
        print("‚ùå Le mod√®le pr√©sente des probl√®mes significatifs")
    
    print(f"\nüìÖ V√©rification effectu√©e le: {time.strftime('%Y-%m-%d %H:%M:%S')}")


if __name__ == "__main__":
    main()