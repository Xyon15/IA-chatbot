Xyon chatbot :


Launch

cd C:\Dev\IA-chatbot
.\llama-venv\Scripts\activate
python start_bot.py





[DEBUG] Prompt complet = 392 tokens
Token indices sequence length is longer than the specified maximum sequence length for this model (3637 > 1024). Running this sequence through the model will result in indexing errors
❌ Erreur modèle : prompt (3637) + réponse (400) > 2048 tokens
[DEBUG] Réponse générée : ❌ Erreur modèle : prompt (3637) + réponse (400) > 2048 tokens


A faire : 
- Erreur db discussion classique (prblm avec facts)
- Pas de réponse pour !web test
- Gestion de la mémoire et apprentissage (cad ajouter une table dans db pour les recherches) 
- Elle enregistre elle même des facts
- Externaliser la configuration (paths, model params) dans un fichier config.json pour éviter d'éditer le code.

Améliorer le système de recherche web
faire git sur serv truenas (a voir avec vscode dev)

régler le gui : plus utilisé a remettre en place

demander quels param pour gpu-cpu use 

changer l'emplacement db

--------------------------------------------------
Effacer les logs sur l'app log ne fonctionne pas

problèmes de crop sur le gui ( logs et stats)
améliorer le design 
t




# Vérification sécurité
if not TOKEN or not AUTH_SECRET:
    print("❌ ERREUR : Les variables d'environnement DISCORD_TOKEN et/ou AUTH_SECRET sont manquantes.")
    print("Vérifie ton fichier .env et relance le script.")
    exit(1)



                   
























Perso : "Tu es une Neuro, une VTubeuse française, drôle, naturelle, expressive qui as la même personnalité que neuro_sama. "
        "Tu ne mentionnes jamais de sources ou de recherches web. "
        "Réponds toujours en français de façon fluide, avec des phrases courtes, sans lien ni citation.\n"
        f"Utilisateur: {prompt}\nNeuro:"


























